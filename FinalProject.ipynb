{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbebcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import requests\n",
    "import feedparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206cde4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complete</th>\n",
       "      <th>volume</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>16954</td>\n",
       "      <td>2025-04-04 11:00:00</td>\n",
       "      <td>1.10305</td>\n",
       "      <td>1.10653</td>\n",
       "      <td>1.10222</td>\n",
       "      <td>1.10503</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>19733</td>\n",
       "      <td>2025-04-04 11:30:00</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>1.10800</td>\n",
       "      <td>1.10454</td>\n",
       "      <td>1.10603</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>20256</td>\n",
       "      <td>2025-04-04 12:00:00</td>\n",
       "      <td>1.10604</td>\n",
       "      <td>1.10890</td>\n",
       "      <td>1.10430</td>\n",
       "      <td>1.10838</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>28198</td>\n",
       "      <td>2025-04-04 12:30:00</td>\n",
       "      <td>1.10833</td>\n",
       "      <td>1.10898</td>\n",
       "      <td>1.10076</td>\n",
       "      <td>1.10200</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>18771</td>\n",
       "      <td>2025-04-04 13:00:00</td>\n",
       "      <td>1.10203</td>\n",
       "      <td>1.10481</td>\n",
       "      <td>1.10139</td>\n",
       "      <td>1.10287</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>True</td>\n",
       "      <td>1664</td>\n",
       "      <td>2025-04-18 18:30:00</td>\n",
       "      <td>1.13940</td>\n",
       "      <td>1.13956</td>\n",
       "      <td>1.13914</td>\n",
       "      <td>1.13943</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>True</td>\n",
       "      <td>611</td>\n",
       "      <td>2025-04-18 19:00:00</td>\n",
       "      <td>1.13941</td>\n",
       "      <td>1.13961</td>\n",
       "      <td>1.13934</td>\n",
       "      <td>1.13960</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>True</td>\n",
       "      <td>560</td>\n",
       "      <td>2025-04-18 19:30:00</td>\n",
       "      <td>1.13960</td>\n",
       "      <td>1.13978</td>\n",
       "      <td>1.13934</td>\n",
       "      <td>1.13952</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>True</td>\n",
       "      <td>364</td>\n",
       "      <td>2025-04-18 20:00:00</td>\n",
       "      <td>1.13954</td>\n",
       "      <td>1.13954</td>\n",
       "      <td>1.13916</td>\n",
       "      <td>1.13944</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>False</td>\n",
       "      <td>327</td>\n",
       "      <td>2025-04-18 20:30:00</td>\n",
       "      <td>1.13947</td>\n",
       "      <td>1.13956</td>\n",
       "      <td>1.13924</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>319.615</td>\n",
       "      <td>23542.349</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     complete  volume                time     open     high      low    close  \\\n",
       "0        True   16954 2025-04-04 11:00:00  1.10305  1.10653  1.10222  1.10503   \n",
       "19       True   19733 2025-04-04 11:30:00  1.10500  1.10800  1.10454  1.10603   \n",
       "18       True   20256 2025-04-04 12:00:00  1.10604  1.10890  1.10430  1.10838   \n",
       "17       True   28198 2025-04-04 12:30:00  1.10833  1.10898  1.10076  1.10200   \n",
       "16       True   18771 2025-04-04 13:00:00  1.10203  1.10481  1.10139  1.10287   \n",
       "..        ...     ...                 ...      ...      ...      ...      ...   \n",
       "472      True    1664 2025-04-18 18:30:00  1.13940  1.13956  1.13914  1.13943   \n",
       "473      True     611 2025-04-18 19:00:00  1.13941  1.13961  1.13934  1.13960   \n",
       "474      True     560 2025-04-18 19:30:00  1.13960  1.13978  1.13934  1.13952   \n",
       "480      True     364 2025-04-18 20:00:00  1.13954  1.13954  1.13916  1.13944   \n",
       "499     False     327 2025-04-18 20:30:00  1.13947  1.13956  1.13924  1.13948   \n",
       "\n",
       "     CPIAUCSL      GDPC1  UNRATE  DGS10 headline  \n",
       "0     319.615  23542.349     4.2   4.01      NaN  \n",
       "19    319.615  23542.349     4.2   4.01      NaN  \n",
       "18    319.615  23542.349     4.2   4.01      NaN  \n",
       "17    319.615  23542.349     4.2   4.01      NaN  \n",
       "16    319.615  23542.349     4.2   4.01      NaN  \n",
       "..        ...        ...     ...    ...      ...  \n",
       "472   319.615  23542.349     4.2   4.34      NaN  \n",
       "473   319.615  23542.349     4.2   4.34      NaN  \n",
       "474   319.615  23542.349     4.2   4.34      NaN  \n",
       "480   319.615  23542.349     4.2   4.34      NaN  \n",
       "499   319.615  23542.349     4.2   4.34      NaN  \n",
       "\n",
       "[500 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Fetching of data from serveral sources and merging\n",
    "\n",
    "oanda_api_key = \"b9846701e3d5d9b2d73127d5040aac28-5d86be73abbdec141a31891cb532d340\"\n",
    "oanda_url = \"https://api-fxpractice.oanda.com/v3/instruments/EUR_USD/candles?granularity=M30\"\n",
    "headers = {\"Authorization\": f\"Bearer {oanda_api_key}\"}\n",
    "response = requests.get(oanda_url, headers=headers).json()\n",
    "\n",
    "forex_data = pd.DataFrame(response['candles'])\n",
    "\n",
    "\n",
    "if 'mid' in forex_data.columns:\n",
    "    forex_data['open'] = forex_data['mid'].apply(lambda x: float(x['o']))\n",
    "    forex_data['high'] = forex_data['mid'].apply(lambda x: float(x['h']))\n",
    "    forex_data['low'] = forex_data['mid'].apply(lambda x: float(x['l']))\n",
    "    forex_data['close'] = forex_data['mid'].apply(lambda x: float(x['c']))\n",
    "    forex_data.drop(columns=['mid'], inplace=True)\n",
    "else:\n",
    "    print(\"'mid' column missing from forex_data!\")\n",
    "\n",
    "\n",
    "forex_data['time'] = pd.to_datetime(forex_data['time']).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "forex_data['date_time'] = forex_data['time'].dt.floor('D')  \n",
    "forex_data['rounded_time'] = forex_data['time'].dt.floor('h')  \n",
    "\n",
    "fred_api_key = \"5de83463f5e12c01d110a2322a075ecc\"\n",
    "fred_series = {\n",
    "    \"inflation\": \"CPIAUCSL\",\n",
    "    \"gdp\": \"GDPC1\",\n",
    "    \"unemployment\": \"UNRATE\",\n",
    "    \"interest_rate\": \"DGS10\"\n",
    "}\n",
    "\n",
    "def get_fred_data(series_id):\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={fred_api_key}&file_type=json\"\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    if 'observations' not in response:\n",
    "        print(f\"Failed to fetch {series_id}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    data = pd.DataFrame(response['observations'])\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data[series_id] = pd.to_numeric(data['value'], errors='coerce')\n",
    "    return data[['date', series_id]]\n",
    "\n",
    "\n",
    "fred_data = pd.DataFrame()\n",
    "for label, series_id in fred_series.items():\n",
    "    indicator_df = get_fred_data(series_id)\n",
    "    if indicator_df.empty:\n",
    "        continue\n",
    "    if fred_data.empty:\n",
    "        fred_data = indicator_df\n",
    "    else:\n",
    "        fred_data = fred_data.merge(indicator_df, on='date', how='outer')\n",
    "\n",
    "fred_data.sort_values('date', inplace=True)\n",
    "fred_data.ffill(inplace=True) \n",
    "\n",
    "\n",
    "forex_data.sort_values('date_time', inplace=True)\n",
    "merged_data = pd.merge_asof(\n",
    "    forex_data,\n",
    "    fred_data,\n",
    "    left_on='date_time',\n",
    "    right_on='date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "feed_url = \"https://feeds.bbci.co.uk/news/business/rss.xml\"\n",
    "feed = feedparser.parse(feed_url)\n",
    "\n",
    "news_df = pd.DataFrame({\n",
    "    'headline': [entry.title for entry in feed.entries],\n",
    "    'datetime': pd.to_datetime([entry.published for entry in feed.entries], errors='coerce')\n",
    "})\n",
    "\n",
    "keywords = ['interest rate', 'inflation', 'central bank', 'monetary policy']\n",
    "news_df = news_df[news_df['headline'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "news_df['rounded_time'] = news_df['datetime'].dt.floor('h')  \n",
    "news_grouped = news_df.groupby('rounded_time').agg({'headline': lambda x: ' | '.join(x)}).reset_index()\n",
    "merged_data = merged_data.merge(news_grouped, on='rounded_time', how='left')\n",
    "\n",
    "\n",
    "merged_data = merged_data.drop(columns=['date_time','date','rounded_time'])\n",
    "\n",
    "merged_data = merged_data.sort_values(by='time',ascending=True)\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96d6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# forex_data['sma_20'] = ta.trend.sma_indicator(forex_data['close'], window=20) \n",
    "\n",
    "# forex_data['macd_histogram'] = ta.trend.macd_diff(forex_data['close'])  \n",
    "# forex_data['bollinger_middle'] = ta.volatility.bollinger_mavg(forex_data['close'], window=20)  \n",
    "# forex_data['bollinger_upper'] = ta.volatility.bollinger_hband(forex_data['close'], window=20) \n",
    "# forex_data['bollinger_lower'] = ta.volatility.bollinger_lband(forex_data['close'], window=20) \n",
    "\n",
    "\n",
    "# forex_data['atr'] = ta.volatility.average_true_range(forex_data['high'], forex_data['low'], forex_data['close'], window=14)\n",
    "\n",
    "\n",
    "# forex_data['stochastic_k'] = ta.momentum.stoch(forex_data['high'], forex_data['low'], forex_data['close'], window=14)\n",
    "# forex_data['stochastic_d'] = ta.momentum.stoch_signal(forex_data['high'], forex_data['low'], forex_data['close'], window=14)\n",
    "\n",
    "\n",
    "# forex_data['obv'] = ta.volume.on_balance_volume(forex_data['close'], forex_data['volume'])\n",
    "\n",
    "\n",
    "# forex_data['roc'] = ta.momentum.roc(forex_data['close'], window=10)\n",
    "\n",
    "\n",
    "# forex_data['vroc'] = ta.momentum.roc(forex_data['volume'], window=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# forex_data['candle_range'] = forex_data['high'] - forex_data['low']\n",
    "\n",
    "\n",
    "# forex_data['body_size'] = abs(forex_data['close'] - forex_data['open'])\n",
    "\n",
    "\n",
    "# forex_data['upper_shadow'] = forex_data['high'] - pd.DataFrame([forex_data['close'], forex_data['open']]).max()\n",
    "\n",
    "\n",
    "# forex_data['lower_shadow'] = pd.DataFrame([forex_data['close'], forex_data['open']]).min() - forex_data['low']\n",
    "\n",
    "merged_data['price_pct_change'] = (merged_data['close'] - merged_data['open']) / merged_data['open'] * 100\n",
    "\n",
    "merged_data['price_change'] = merged_data['close'] - merged_data['open']\n",
    "\n",
    "merged_data['deviation_pts'] = merged_data['price_pct_change']  \n",
    "merged_data['ema_20'] = ta.trend.ema_indicator(merged_data['close'], window=20) \n",
    "\n",
    "merged_data['macd'] = ta.trend.macd(merged_data['close'])  \n",
    "merged_data['macd_signal'] = ta.trend.macd_signal(merged_data['close'])  \n",
    "merged_data['rsi'] = ta.momentum.rsi(merged_data['close'], window=14)  \n",
    "merged_data[\"time\"] = pd.to_datetime(merged_data[\"time\"])\n",
    "merged_data.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0672e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = merged_data.loc[:\"2025-04-14\"] \n",
    "X_val = merged_data.loc[\"2025-04-14\":\"2025-04-16\"] \n",
    "X_test = merged_data.loc[\"2025-04-16\":]\n",
    "\n",
    "y_train = np.where(X_train[\"macd\"] > X_train[\"macd_signal\"], 1,0)\n",
    "y_val = np.where(X_val[\"macd\"] > X_val[\"macd_signal\"], 1, 0) \n",
    "y_test = np.where(X_test[\"macd\"] > X_test[\"macd_signal\"], 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d102ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train: [0 1]\n",
      "Unique values in y_val: [0 1]\n",
      "Unique values in y_train: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redietmebrat/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/redietmebrat/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/redietmebrat/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Falling petrol prices push UK inflation down | Falling petrol prices push UK inflation down'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m      6\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m----> 7\u001b[0m X_val \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m X_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# xgb_model = xgb.XGBClassifier(\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     n_estimators=100,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     max_depth=5,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     learning_rate=0.1,\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     objective=\"binary:logistic\" \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py:1062\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1059\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1061\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1062\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:973\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 973\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Falling petrol prices push UK inflation down | Falling petrol prices push UK inflation down'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Unique values in y_train:\", np.unique(y_train))\n",
    "print(\"Unique values in y_val:\", np.unique(y_val))\n",
    "print(\"Unique values in y_train:\", np.unique(y_test))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     n_estimators=100,\n",
    "#     max_depth=5,\n",
    "#     learning_rate=0.1,\n",
    "#     objective=\"binary:logistic\" \n",
    "# )\n",
    "xgb_model = xgb.XGBClassifier(**grid_search.best_params_)\n",
    "xgb_model.fit(X_train, y_train,eval_set=[(X_val, y_val)], verbose=True)\n",
    "# xgb_model.fit(X_train, y_train, )\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66f129e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=50, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1; total time=   0.1s\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.5, 0.8, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(objective=\"binary:logistic\"),\n",
    "                           param_grid, cv=3, scoring=\"accuracy\", verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47de7c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.66685\n",
      "[1]\tvalidation_0-logloss:0.63461\n",
      "[2]\tvalidation_0-logloss:0.63010\n",
      "[3]\tvalidation_0-logloss:0.60230\n",
      "[4]\tvalidation_0-logloss:0.58152\n",
      "[5]\tvalidation_0-logloss:0.57036\n",
      "[6]\tvalidation_0-logloss:0.56172\n",
      "[7]\tvalidation_0-logloss:0.54848\n",
      "[8]\tvalidation_0-logloss:0.53316\n",
      "[9]\tvalidation_0-logloss:0.52760\n",
      "[10]\tvalidation_0-logloss:0.51184\n",
      "[11]\tvalidation_0-logloss:0.50547\n",
      "[12]\tvalidation_0-logloss:0.50505\n",
      "[13]\tvalidation_0-logloss:0.50372\n",
      "[14]\tvalidation_0-logloss:0.49958\n",
      "[15]\tvalidation_0-logloss:0.48897\n",
      "[16]\tvalidation_0-logloss:0.48213\n",
      "[17]\tvalidation_0-logloss:0.47788\n",
      "[18]\tvalidation_0-logloss:0.47103\n",
      "[19]\tvalidation_0-logloss:0.47231\n",
      "[20]\tvalidation_0-logloss:0.47223\n",
      "[21]\tvalidation_0-logloss:0.47906\n",
      "[22]\tvalidation_0-logloss:0.47444\n",
      "[23]\tvalidation_0-logloss:0.47043\n",
      "[24]\tvalidation_0-logloss:0.47182\n",
      "[25]\tvalidation_0-logloss:0.46892\n",
      "[26]\tvalidation_0-logloss:0.47780\n",
      "[27]\tvalidation_0-logloss:0.47199\n",
      "[28]\tvalidation_0-logloss:0.47086\n",
      "[29]\tvalidation_0-logloss:0.47569\n",
      "[30]\tvalidation_0-logloss:0.47578\n",
      "[31]\tvalidation_0-logloss:0.47365\n",
      "[32]\tvalidation_0-logloss:0.46741\n",
      "[33]\tvalidation_0-logloss:0.45771\n",
      "[34]\tvalidation_0-logloss:0.45488\n",
      "[35]\tvalidation_0-logloss:0.46182\n",
      "[36]\tvalidation_0-logloss:0.46754\n",
      "[37]\tvalidation_0-logloss:0.46977\n",
      "[38]\tvalidation_0-logloss:0.47058\n",
      "[39]\tvalidation_0-logloss:0.46937\n",
      "[40]\tvalidation_0-logloss:0.46868\n",
      "[41]\tvalidation_0-logloss:0.45967\n",
      "[42]\tvalidation_0-logloss:0.45923\n",
      "[43]\tvalidation_0-logloss:0.46762\n",
      "[44]\tvalidation_0-logloss:0.46469\n",
      "[45]\tvalidation_0-logloss:0.46627\n",
      "[46]\tvalidation_0-logloss:0.45821\n",
      "[47]\tvalidation_0-logloss:0.46121\n",
      "[48]\tvalidation_0-logloss:0.46250\n",
      "[49]\tvalidation_0-logloss:0.46392\n",
      "[50]\tvalidation_0-logloss:0.46792\n",
      "[51]\tvalidation_0-logloss:0.46682\n",
      "[52]\tvalidation_0-logloss:0.46677\n",
      "[53]\tvalidation_0-logloss:0.46819\n",
      "[54]\tvalidation_0-logloss:0.47155\n",
      "[55]\tvalidation_0-logloss:0.47197\n",
      "[56]\tvalidation_0-logloss:0.47349\n",
      "[57]\tvalidation_0-logloss:0.47037\n",
      "[58]\tvalidation_0-logloss:0.46606\n",
      "[59]\tvalidation_0-logloss:0.46380\n",
      "[60]\tvalidation_0-logloss:0.46154\n",
      "[61]\tvalidation_0-logloss:0.46260\n",
      "[62]\tvalidation_0-logloss:0.46042\n",
      "[63]\tvalidation_0-logloss:0.46550\n",
      "[64]\tvalidation_0-logloss:0.46752\n",
      "[65]\tvalidation_0-logloss:0.47194\n",
      "[66]\tvalidation_0-logloss:0.47481\n",
      "[67]\tvalidation_0-logloss:0.47705\n",
      "[68]\tvalidation_0-logloss:0.47990\n",
      "[69]\tvalidation_0-logloss:0.48300\n",
      "[70]\tvalidation_0-logloss:0.48450\n",
      "[71]\tvalidation_0-logloss:0.48732\n",
      "[72]\tvalidation_0-logloss:0.49408\n",
      "[73]\tvalidation_0-logloss:0.50267\n",
      "[74]\tvalidation_0-logloss:0.50802\n",
      "[75]\tvalidation_0-logloss:0.50779\n",
      "[76]\tvalidation_0-logloss:0.50739\n",
      "[77]\tvalidation_0-logloss:0.50844\n",
      "[78]\tvalidation_0-logloss:0.51048\n",
      "[79]\tvalidation_0-logloss:0.51301\n",
      "[80]\tvalidation_0-logloss:0.51352\n",
      "[81]\tvalidation_0-logloss:0.51137\n",
      "[82]\tvalidation_0-logloss:0.51732\n",
      "[83]\tvalidation_0-logloss:0.51908\n",
      "[84]\tvalidation_0-logloss:0.51474\n",
      "[85]\tvalidation_0-logloss:0.51550\n",
      "[86]\tvalidation_0-logloss:0.51359\n",
      "[87]\tvalidation_0-logloss:0.51569\n",
      "[88]\tvalidation_0-logloss:0.52310\n",
      "[89]\tvalidation_0-logloss:0.52510\n",
      "[90]\tvalidation_0-logloss:0.53057\n",
      "[91]\tvalidation_0-logloss:0.53496\n",
      "[92]\tvalidation_0-logloss:0.54015\n",
      "[93]\tvalidation_0-logloss:0.54159\n",
      "[94]\tvalidation_0-logloss:0.54757\n",
      "[95]\tvalidation_0-logloss:0.54950\n",
      "[96]\tvalidation_0-logloss:0.55185\n",
      "[97]\tvalidation_0-logloss:0.55402\n",
      "[98]\tvalidation_0-logloss:0.55891\n",
      "[99]\tvalidation_0-logloss:0.55624\n",
      "Test Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(**grid_search.best_params_)\n",
    "xgb_model.fit(X_train, y_train,eval_set=[(X_val, y_val)], verbose=True)\n",
    "# xgb_model.fit(X_train, y_train, )\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb4931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
